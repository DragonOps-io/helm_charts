apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.app.service.name }}
spec:
  replicas: {{ .Values.app.pod.initialCount }}
  progressDeadlineSeconds: 600
  selector:
    matchLabels:
      app: {{ .Values.app.service.name }}
  template:
    metadata:
      labels:
        app: {{ .Values.app.service.name }}
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - {{ .Values.app.service.name }}
              topologyKey: "kubernetes.io/hostname"
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 50
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - {{ .Values.app.service.name }}
                topologyKey: "topology.kubernetes.io/zone"
      {{- if .Values.iam.service_account_name }}
      serviceAccountName:  {{ .Values.iam.service_account_name }}
      {{ end }}
      terminationGracePeriodSeconds: 30
      shareProcessNamespace: true
      containers:
        - image: "{{ .Values.image.url }}/{{ .Values.image.name }}:{{ .Values.image.tag }}"
          imagePullPolicy: Always
          name: {{ .Values.app.service.name }}
          ports:
            - containerPort: {{ .Values.app.pod.port }}
          livenessProbe:
            httpGet:
              path: {{ .Values.app.pod.healthCheckPath }}
              port: {{ .Values.app.pod.port }}
            timeoutSeconds: 10
            initialDelaySeconds: 10
          readinessProbe:
            httpGet:
              path: {{ .Values.app.pod.healthCheckPath }}
              port: {{ .Values.app.pod.port }}
            timeoutSeconds: 10
            initialDelaySeconds: 10
            successThreshold: 2
          resources:
            requests:
              memory: {{ .Values.app.resources.requests.memory }}
              cpu: {{ .Values.app.resources.requests.cpu }}
            limits:
              memory: {{ .Values.app.resources.limits.memory }}
              cpu: {{ .Values.app.resources.limits.cpu }}
          env:
            - name: OTEL_RESOURCE_ATTRIBUTES
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.app.secretName }}
                  key: OTEL_RESOURCE_ATTRIBUTES
          envFrom:
            - secretRef:
                name: {{ .Values.app.secretName }}
            {{- range .Values.app.database_secret_names_to_use }}
            - secretRef:
                name: {{ . }}
            {{- end }}
          securityContext:
            capabilities:
              drop:
                - all
        - name: beyla
          image: grafana/beyla:latest
          securityContext: # Privileges are required to install the eBPF probes
            privileged: true
          env:
            - name: BEYLA_NETWORK_METRICS
              value: "true"
            - name: OTEL_TRACES_SAMPLER
              value: "always_on"
            - name: BEYLA_SERVICE_NAME
              value: "{{ .Values.app.service.name }}"
            - name: BEYLA_OPEN_PORT
              value: "{{ .Values.app.pod.port }}"
            - name: BEYLA_KUBE_METADATA_ENABLE
              value: "true"
            - name: OTEL_EXPORTER_OTLP_METRICS_ENDPOINT
              value: "http://{{ .Values.app.service.observability.endpoint }}:4318/v1/metrics"
            - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
              value: "http://{{ .Values.app.service.observability.endpoint }}:4318/v1/traces"
        - name: otel-collector
          image: otel/opentelemetry-collector-contrib:0.117.0
          securityContext: # Privileges are required to install the eBPF probes
            privileged: true
          env:
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: "service.name={{ .Values.app.service.name }},deployment.environment={{ .Release.Namespace }}"
            - name: K8S_NODE_NAME  # Needed for kubeletstats
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          args: [ "--config=/etc/otel-collector-config.yaml" ]
          volumeMounts:
            - mountPath: /etc/otel-collector-config.yaml
              name: otel-config-v2
              subPath: otel-collector-config.yaml
        - name: fluent-bit
          image: fluent/fluent-bit:latest
          volumeMounts:
            - name: varlog
              mountPath: /var/log
            - name: fluent-bit-config
              mountPath: /fluent-bit/etc/

      volumes:
        - name: varlog
          hostPath:
            path: /var/log
        - name: fluent-bit-config
          configMap:
            name: fluent-bit-config
        - configMap:
            defaultMode: 420
            items:
              - key: collector.yaml
                path: otel-collector-config.yaml
            name: otel-collector-config-v2
          name: otel-config-v2
      restartPolicy: Always
status: { }
---
apiVersion: v1
kind: ConfigMap
immutable: false
metadata:
  name: otel-collector-config-v2
data:
  collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      kubeletstats:
        collection_interval: 10s
        auth_type: serviceAccount
        endpoint: "https://${env:K8S_NODE_NAME}:10250"  # Talks to Kubelet
        insecure_skip_verify: true
        metric_groups:
          - pod
          - container
    processors:
      batch:
      resourcedetection:
        detectors: [ env, eks ]
    exporters:
      otlp/metrics:
        endpoint: {{ .Values.app.service.observability.endpoint }}:4317
        tls:
          insecure: true
      otlp/traces:
        endpoint: {{ .Values.app.service.observability.endpoint }}:4317
        tls:
          insecure: true
    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
    service:
      extensions: [health_check]
      pipelines:
        traces:
          receivers: [otlp]
          processors: [resourcedetection,batch]
          exporters: [otlp/traces]
        metrics:
          receivers: [otlp,kubeletstats]
          processors: [resourcedetection,batch]
          exporters: [otlp/metrics]
---
apiVersion: v1
kind: ConfigMap
immutable: false
metadata:
  name: fluent-bit-config
data:
  fluent-bit.conf: |
    [SERVICE]
        Flush 1
        Log_Level info
        Daemon Off
        Parsers_File parsers.conf
        HTTP_Server On
        HTTP_Listen 0.0.0.0
        HTTP_Port 2020

    [INPUT]
        Name tail
        Path /var/log/containers/*.log  # Collect logs from all containers
        Parser docker
        Tag kube.*

    [FILTER]
        Name kubernetes
        Match kube.*
        Kube_URL https://kubernetes.default.svc.cluster.local:443
        Merge_Log On
        K8S-Logging.Parser On
        K8S-Logging.Exclude Off

    [OUTPUT]
        Name loki
        Match kube.*
        Host http://{{ .Values.app.service.observability.endpoint}}
        Port 3100
        Labels app="{{.Values.app.service.name}}", environment="{{.Release.Name}}"
        Auto_Kubernetes_Labels On